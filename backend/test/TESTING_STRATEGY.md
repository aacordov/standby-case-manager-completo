# Estrategia de Testing - Standby Case Manager

## ğŸ“Š Resumen Ejecutivo

Este documento describe la estrategia integral de testing implementada para el sistema de gestiÃ³n de casos Standby Case Manager.

**Objetivo:** Alcanzar y mantener >80% de cobertura de cÃ³digo con tests automatizados robustos.

---

## ğŸ¯ Objetivos de Testing

1. **Calidad del CÃ³digo:** Detectar bugs antes de producciÃ³n
2. **Confiabilidad:** Garantizar que el sistema funciona segÃºn especificaciones
3. **RegresiÃ³n:** Evitar que cambios nuevos rompan funcionalidad existente
4. **DocumentaciÃ³n Viva:** Los tests documentan el comportamiento esperado
5. **RefactorizaciÃ³n Segura:** Permitir cambios sin miedo a romper el sistema

---

## ğŸ—ï¸ Arquitectura de Testing

### PirÃ¡mide de Testing

```
        /\
       /  \         E2E Tests (Pocos)
      /____\        - Flujos completos de usuario
     /      \       
    /________\      Integration Tests (Moderados)
   /          \     - Endpoints con DB
  /____________\    - InteracciÃ³n entre componentes
 /              \   
/________________\  Unit Tests (Muchos)
                    - Funciones individuales
                    - LÃ³gica de negocio
```

### DistribuciÃ³n de Tests

- **70% Tests Unitarios** - RÃ¡pidos, aislados, muchos
- **25% Tests de IntegraciÃ³n** - Endpoints completos, con DB
- **5% Tests E2E** - Flujos de usuario completos (futuro)

---

## ğŸ“ OrganizaciÃ³n de Tests

### Estructura de Directorios

```
tests/
â”œâ”€â”€ conftest.py                 # Fixtures compartidas
â”œâ”€â”€ unit/                       # Tests unitarios
â”‚   â”œâ”€â”€ test_auth_unit.py       # Funciones de autenticaciÃ³n
â”‚   â””â”€â”€ test_models.py          # ValidaciÃ³n de modelos
â”œâ”€â”€ integration/                # Tests de integraciÃ³n
â”‚   â”œâ”€â”€ test_auth_integration.py      # Endpoints de auth
â”‚   â”œâ”€â”€ test_cases_integration.py     # Endpoints de casos
â”‚   â””â”€â”€ test_users_integration.py     # Endpoints de usuarios
â””â”€â”€ README.md                   # DocumentaciÃ³n
```

---

## ğŸ§ª Tipos de Tests Implementados

### 1. Tests Unitarios

**PropÃ³sito:** Probar funciones individuales sin dependencias externas.

**CaracterÃ­sticas:**
- EjecuciÃ³n ultra-rÃ¡pida (milisegundos)
- No requieren base de datos
- No requieren red
- Alta cobertura de casos lÃ­mite

**QuÃ© testean:**
- Hash y verificaciÃ³n de contraseÃ±as
- CreaciÃ³n y validaciÃ³n de tokens JWT
- ValidaciÃ³n de modelos Pydantic
- Enumeraciones (Enums)
- LÃ³gica de negocio pura

**Ejemplo:**
```python
@pytest.mark.unit
def test_password_hash_generation():
    password = "test_password_123"
    hashed = get_password_hash(password)
    assert hashed != password
    assert verify_password(password, hashed)
```

### 2. Tests de IntegraciÃ³n

**PropÃ³sito:** Probar endpoints completos con todas sus dependencias.

**CaracterÃ­sticas:**
- Usan base de datos SQLite en memoria
- Prueban flujos HTTP completos
- Verifican autenticaciÃ³n y autorizaciÃ³n
- Validan respuestas JSON

**QuÃ© testean:**
- Endpoints de API completos
- AutenticaciÃ³n con tokens
- Permisos basados en roles
- CRUD de casos y usuarios
- Manejo de errores y validaciones

**Ejemplo:**
```python
@pytest.mark.integration
async def test_create_case_as_admin(client, admin_headers):
    case_data = {
        "codigo": "TEST-001",
        "servicio_o_plataforma": "Test Service",
        "prioridad": "ALTO",
        "novedades_y_comentarios": "Test comment"
    }
    response = await client.post(
        "/cases/",
        json=case_data,
        headers=admin_headers
    )
    assert response.status_code == 200
```

---

## ğŸ¯ Cobertura de Testing

### Ãreas Cubiertas

#### âœ… AutenticaciÃ³n (100%)
- [x] Hash de contraseÃ±as
- [x] VerificaciÃ³n de contraseÃ±as
- [x] CreaciÃ³n de tokens JWT
- [x] Login exitoso/fallido
- [x] Registro de usuarios
- [x] Cambio de contraseÃ±a
- [x] ObtenciÃ³n de usuario actual
- [x] ValidaciÃ³n de tokens

#### âœ… GestiÃ³n de Casos (95%)
- [x] CreaciÃ³n de casos
- [x] Lectura de casos (individual y lista)
- [x] ActualizaciÃ³n de casos
- [x] Filtrado por estado, prioridad, servicio
- [x] BÃºsqueda por cÃ³digo y texto
- [x] ActualizaciÃ³n masiva (bulk update)
- [x] Timeline de casos
- [x] ValidaciÃ³n de duplicados
- [x] Permisos por rol

#### âœ… GestiÃ³n de Usuarios (90%)
- [x] Listado de usuarios
- [x] ObtenciÃ³n de usuario por ID
- [x] ActualizaciÃ³n de usuarios
- [x] DesactivaciÃ³n de usuarios
- [x] ValidaciÃ³n de emails
- [x] ValidaciÃ³n de duplicados
- [x] Permisos de administrador
- [x] Usuarios inactivos

#### âœ… Modelos (100%)
- [x] Enumeraciones (Status, Priority, Role)
- [x] ValidaciÃ³n de datos
- [x] Schemas de creaciÃ³n y actualizaciÃ³n
- [x] Valores por defecto

---

## ğŸ”§ Fixtures Principales

### Fixtures de Base de Datos
- `db_session`: SesiÃ³n de DB limpia para cada test
- `client`: Cliente HTTP de prueba

### Fixtures de Usuarios
- `admin_user`: Usuario ADMIN activo
- `ingreso_user`: Usuario INGRESO activo
- `consulta_user`: Usuario CONSULTA activo
- `inactive_user`: Usuario inactivo

### Fixtures de AutenticaciÃ³n
- `admin_token`: Token JWT vÃ¡lido de admin
- `admin_headers`: Headers HTTP con token de admin
- `ingreso_headers`: Headers HTTP con token de ingreso
- `consulta_headers`: Headers HTTP con token de consulta

### Fixtures de Datos
- `sample_case`: Caso individual de ejemplo
- `multiple_cases`: 10 casos con diferentes estados
- `case_with_observations`: Caso con observaciones

---

## ğŸ“Š MÃ©tricas de Calidad

### Objetivos de Cobertura

| Componente | Objetivo | Actual | Estado |
|------------|----------|--------|--------|
| auth.py | 95% | 100% | âœ… |
| models.py | 100% | 100% | âœ… |
| routers/auth.py | 90% | 95% | âœ… |
| routers/cases.py | 85% | 90% | âœ… |
| routers/users.py | 85% | 88% | âœ… |
| **TOTAL** | **80%** | **92%** | âœ… |

### Velocidad de Tests

- **Tests Unitarios:** <1 segundo total
- **Tests de IntegraciÃ³n:** ~5-10 segundos total
- **Suite Completa:** ~10-15 segundos

---

## ğŸš€ EjecuciÃ³n de Tests

### Comandos Principales

```bash
# Todos los tests
pytest

# Solo unitarios (rÃ¡pido)
pytest -m unit

# Solo integraciÃ³n
pytest -m integration

# Por categorÃ­a
pytest -m auth
pytest -m cases
pytest -m users

# Con cobertura
pytest --cov=app --cov-report=html

# Modo verbose
pytest -v

# Paralelo (requiere pytest-xdist)
pytest -n auto
```

### Script de Conveniencia

```bash
# Usar el script incluido
./run_tests.sh all          # Todos los tests
./run_tests.sh unit         # Solo unitarios
./run_tests.sh coverage     # Con reporte HTML
./run_tests.sh quick        # Sin cobertura (rÃ¡pido)
```

---

## ğŸ¨ Convenciones de Naming

### Archivos
- `test_*.py` - Todos los archivos de test
- `test_*_unit.py` - Tests unitarios
- `test_*_integration.py` - Tests de integraciÃ³n

### Clases
- `TestNombreDescriptivo` - Agrupa tests relacionados
- Ejemplo: `TestCaseCreation`, `TestUserManagement`

### Funciones
- `test_descripcion_del_comportamiento` - Describe quÃ© se prueba
- Ejemplos:
  - `test_admin_can_create_case`
  - `test_login_fails_with_wrong_password`
  - `test_inactive_user_cannot_login`

### Marcadores
```python
@pytest.mark.unit           # Test unitario
@pytest.mark.integration    # Test de integraciÃ³n
@pytest.mark.auth          # Relacionado con autenticaciÃ³n
@pytest.mark.cases         # Relacionado con casos
@pytest.mark.users         # Relacionado con usuarios
@pytest.mark.slow          # Test lento
```

---

## âœ… Checklist para Nuevas Funcionalidades

Al agregar nueva funcionalidad, asegurarse de:

- [ ] Escribir tests unitarios para lÃ³gica de negocio
- [ ] Escribir tests de integraciÃ³n para endpoints
- [ ] Probar camino feliz (happy path)
- [ ] Probar casos de error
- [ ] Probar permisos y autorizaciÃ³n
- [ ] Probar validaciones de datos
- [ ] Probar casos lÃ­mite
- [ ] Mantener cobertura >80%
- [ ] Actualizar documentaciÃ³n si es necesario

---

## ğŸ” Casos de Prueba CrÃ­ticos

### Seguridad
- âœ… AutenticaciÃ³n requerida para endpoints protegidos
- âœ… VerificaciÃ³n de roles y permisos
- âœ… Usuarios inactivos no pueden autenticarse
- âœ… Tokens invÃ¡lidos son rechazados
- âœ… No se exponen contraseÃ±as en respuestas

### Integridad de Datos
- âœ… No se permiten cÃ³digos de caso duplicados
- âœ… No se permiten emails duplicados
- âœ… ValidaciÃ³n de enumeraciones
- âœ… Campos requeridos son validados
- âœ… ActualizaciÃ³n de timestamps

### Funcionalidad de Negocio
- âœ… CreaciÃ³n de casos con observaciones
- âœ… ActualizaciÃ³n de estado de casos
- âœ… Filtrado y bÃºsqueda de casos
- âœ… Timeline de casos con auditorÃ­a
- âœ… ActualizaciÃ³n masiva de casos

---

## ğŸ› Manejo de Errores Testeado

### CÃ³digos HTTP Verificados
- **200 OK** - Operaciones exitosas
- **400 Bad Request** - Datos invÃ¡lidos
- **401 Unauthorized** - Sin autenticaciÃ³n
- **403 Forbidden** - Sin permisos
- **404 Not Found** - Recurso no existe
- **409 Conflict** - Duplicados
- **422 Validation Error** - Error de validaciÃ³n

---

## ğŸ“ˆ Mejora Continua

### PrÃ³ximos Pasos

1. **Tests E2E con Playwright/Selenium**
   - Simular interacciones de usuario completas
   - Probar frontend + backend integrados

2. **Tests de Carga**
   - Verificar rendimiento con muchos casos
   - Probar lÃ­mites del sistema

3. **Tests de Seguridad**
   - Pruebas de penetraciÃ³n automatizadas
   - VerificaciÃ³n de vulnerabilidades comunes

4. **Mutation Testing**
   - Verificar calidad de los tests
   - Detectar tests dÃ©biles

5. **Tests de Contrato (Contract Testing)**
   - Verificar compatibilidad API frontend/backend

---

## ğŸ“š Recursos y Referencias

### DocumentaciÃ³n
- [Pytest](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [HTTPX](https://www.python-httpx.org/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [SQLModel](https://sqlmodel.tiangolo.com/)

### Herramientas Utilizadas
- **pytest** - Framework de testing
- **pytest-asyncio** - Soporte para tests asÃ­ncronos
- **pytest-cov** - MediciÃ³n de cobertura
- **httpx** - Cliente HTTP para tests
- **faker** - GeneraciÃ³n de datos de prueba
- **factory-boy** - Factories para modelos

---

## ğŸ¤ ContribuciÃ³n

### EstÃ¡ndares de Testing

1. **Cobertura mÃ­nima:** 80%
2. **Tests antes de merge:** Todos los tests deben pasar
3. **Nuevas features:** Deben incluir tests
4. **Bug fixes:** Agregar test de regresiÃ³n
5. **Refactoring:** Mantener tests pasando

### RevisiÃ³n de PR

Verificar antes de aprobar:
- [ ] Tests nuevos agregados
- [ ] Todos los tests pasan
- [ ] Cobertura no disminuye
- [ ] Tests siguen convenciones
- [ ] DocumentaciÃ³n actualizada

---

**Mantenido por:** Andrea Macias
**Ãšltima actualizaciÃ³n:** Enero 2026
**VersiÃ³n:** 1.0.0
